my data <- read.table("Twitter_Data_1",header=TRUE,sep=",")
my_data <- read.table("Twitter_Data_1",header=TRUE,sep=",")
my_data <- read.table("\Downloads|Twitter_Data_1",header=TRUE,sep=",")
my_data <- read.table("\Downloads\Twitter_Data_1",header=TRUE,sep=",")
my_data <- read.table("Downloads\Twitter_Data_1",header=TRUE,sep=",")
setwd("C:\\Users\\GireshMulani\\Downloads")
setwd(Users\\GireshMulani\\Downloads")
setwd("Users\\GireshMulani\\Downloads")
setwd("Users\\Giresh Mulani\\Downloads")
q()
?dbinom
pnorm()
pnorm(q, mean = -0.33, sd = 1, lower.tail = TRUE, log.p = FALSE)
pnorm(-0.33)
Y=0:10
dgeom(Y, 0.5)
plot(dgeom(Y, 0.5))
plot(dgeom(Y, 0.5), x-axis = y, y-axis = probability)
plot(dgeom(Y, 0.5), xlab = y, ylab = probability)
plot(dgeom(Y, 0.5), xlab = Y, ylab = probability)
plot(dgeom(Y, 0.5), xlab = Y, ylab = p)
plot(dgeom(Y, 0.5), xlab = Y, ylab = "probability")
plot(dgeom(Y, 0.5), xlab = "y", ylab = "probability")
plot(dgeom(Y, 1/3), xlab = "y", ylab = "probability")
plot(dgeom(Y, 0.2), xlab = "y", ylab = "probability")
legend(plot(dgeom(Y, 0.2), xlab = "y", ylab = "probability"))
x = 1
(213.1-292.7)/sqrt((1135.4971/8) + (20655.634/8))
17/18
binom.test(17, 18, p=0.5)
binom.test(10,18,0.5)
source('~/Google Drive/Monash/FIT2086/S2-18/Week 11/my.prediction.stats.R')
install.packages("pROC")
setwd("~/Google Drive/Monash/FIT2086/S2-18/Week 11")
source('~/Google Drive/Monash/FIT2086/S2-18/Week 11/my.prediction.stats.R')
install.packages("pROC")
install.packages("ggplot2")
install.packages("rlang")
install.packages("ggplot2")
install.packages("pROC")
source('~/Google Drive/Monash/FIT2086/S2-18/Week 11/my.prediction.stats.R')
fit = glm(DIABETES ~ ., pima.train, family=binomial)
pima.train <- read.csv("pima.train.csv")
fit = glm(DIABETES ~ ., pima.train, family=binomial)
my.pred.stats(predict(fit,pima.train,type="response"), pima.train$DIABETES)
rv = my.pred.stats(predict(fit,pima.train,type="response"), pima.train$DIABETES, display=F)
rv
boot.auc = function(formula, data, indices)
{
# Create a bootstrapped version of our data
d = data[indices,]
# Fit a logistic regression to the bootstrapped data
fit = glm(formula, d, family=binomial)
# Compute the AUC and return it
target = as.character(fit$terms[[2]])
rv = my.pred.stats(predict(fit,d,type="response"), d[,target], display=F)
return(rv$auc)
}
bs = boot(data=pima.train, statistic=boot.auc, R=1000, formula=DIABETES ~  .)
library(boot)
bs = boot(data=pima.train, statistic=boot.auc, R=1000, formula=DIABETES ~  .)
boot.ci(bs,conf=0.95,type="bca")
plot(bs)
my.pred.stats(predict(fit,pima.test,type="response"), pima.test$DIABETES)
pima.test <- read.csv("pima.tests.csv")
pima.test <- read.csv("pima.test.csv")
my.pred.stats(predict(fit,pima.test,type="response"), pima.test$DIABETES)
source('~/Google Drive/Monash/FIT2086/S2-18/Week 11/perm.log.reg.R')
rv = perm.log.reg(DIABETES ~ ., pima.train, R=1000)
rv = perm.log.reg(DIABETES ~ ., pima.train, R=10000)
summary(fit)
hist(rv$perm.coef[,"INS"])
hist(rv$perm.coef[,"BP"])
install.packages(c("BH", "MASS", "Matrix", "R6", "Rcpp", "bestglm", "cluster", "codetools", "foreach", "foreign", "glmnet", "grpreg", "hms", "igraph", "irlba", "iterators", "lattice", "mgcv", "naivebayes", "pkgconfig", "randomForest", "rpart", "survival", "tibble"))
